{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization Notebook\n",
    "\n",
    "### Goal: I have reached a point where I believe my model suffers from bias, and am looking for a way to add complexity without overfitting, so I am going to implement regularization to attempt to achieve that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "ames = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to clean the data\n",
    "def clean_ames_data(df):\n",
    "    '''Generalized function to clean a sample of Ames Housing Data'''\n",
    "    \n",
    "    # convert column names to useable format\n",
    "    df.columns = [x.lower().replace(' ','_') for x in df.columns]\n",
    "    \n",
    "    # drop 'id' and 'pid' columns\n",
    "    #df.drop(['id','pid'], axis=1, inplace=True)\n",
    "\n",
    "    # Dealing with NaN values. Handling the special case of Masonry Veneer Type first\n",
    "    \n",
    "    df['mas_vnr_type'].fillna(value = 'None', inplace = True) # Assuming 'NaN' should be 'None' for Masonry Type\n",
    "    df['mas_vnr_area'].fillna(value = 0.0, inplace = True) # Assuming masonry area is 0.0 for houses with 'NaN' type\n",
    "    \n",
    "    # for categorical variables, the missing values should actually be marked 'NA'\n",
    "    nulls = df.columns[df.isnull().any()]\n",
    "    for col in df[nulls].select_dtypes(include = 'object').columns:\n",
    "        df[col].fillna(value = 'NA', inplace = True)\n",
    "    \n",
    "    # filtering for houses with no basement, replacing numerical columns 'NaNs' with 0.0\n",
    "    no_bsmt = df['bsmt_qual'] == 'NA'    \n",
    "    for col in df[no_bsmt].filter(regex = 'bsmt'):\n",
    "        df[col].fillna(value = 0.0, inplace = True)\n",
    "        \n",
    "    # use the same procedure to handle numerical columns for houses with no garage\n",
    "    no_garage = df['garage_type'] == 'NA' \n",
    "    for col in df[no_garage].filter(regex = 'garage'):\n",
    "        df[col].fillna(value = 0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "clean_ames_data(ames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X an y\n",
    "X = ames.loc[:,ames.columns != 'saleprice']\n",
    "y = ames['saleprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical variable for Location\n",
    "X['Location'] = X['neighborhood']\n",
    "X['Location'].replace({'MeadowV':'Low','IDOTRR': 'Low','BrDale': 'Low','OldTown': 'Low',\n",
    "                                'Edwards':'Low','BrkSide':'Low', 'Landmrk': 'LowMed','Sawyer': 'LowMed',\n",
    "                                'SWISU':'LowMed','NAmes':'LowMed','NPkVill':'LowMed','Blueste':'LowMed',\n",
    "                                'Mitchel':'LowMed','Gilbert':'MedHigh','Greens':'MedHigh','SawyerW':'MedHigh',\n",
    "                                'NWAmes':'MedHigh','Blmngtn':'MedHigh','CollgCr':'MedHigh','ClearCr':'MedHigh',\n",
    "                                'Crawfor':'MedHigh','Somerst':'High','Timber':'High','Veenker':'High','GrnHill':'High',\n",
    "                                'NoRidge':'High','NridgHt':'High','StoneBr':'High'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummy variables I will need\n",
    "\n",
    "# define a function to create the dummy variables I need\n",
    "style_mask = X['house_style'] == '2.5Fin'\n",
    "\n",
    "# Create a dummy to indicate house style is 2.5Fin\n",
    "X['StyleDummy'] = np.where(X['house_style'] == '2.5Fin', 1, 0)\n",
    "\n",
    "# Create a dummy for being adjacent to or near a positive feature\n",
    "X['PosFeature'] = np.where((X['condition_2'] == 'PosN') | (X['condition_2'] == 'PosA'), 1, 0)\n",
    "\n",
    "# Create dummies for Total Rooms Above Grade\n",
    "X = pd.get_dummies(X, columns = ['ms_zoning', 'full_bath',\n",
    "                                 'sale_type','central_air','Location',\n",
    "                                'garage_cars','exter_qual'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['overall_qual', 'garage_area','gr_liv_area','year_built','totrms_abvgrd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns = ['StyleDummy','PosFeature',\n",
    "                 'full_bath_1','full_bath_2','full_bath_3','full_bath_4',\n",
    "                 'central_air_Y','Location_Low','Location_LowMed','Location_MedHigh',\n",
    "                 'garage_cars_1.0','garage_cars_2.0','garage_cars_3.0','garage_cars_4.0','garage_cars_5.0',\n",
    "                 'exter_qual_Fa','exter_qual_Gd','exter_qual_TA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns2 = ['StyleDummy','PosFeature',\n",
    "                 'central_air_Y','Location_Low','Location_LowMed','Location_MedHigh',\n",
    "                 'exter_qual_Fa','exter_qual_Gd','exter_qual_TA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns3 = ['central_air_Y','Location_Low','Location_LowMed','Location_MedHigh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_columns4 = ['PosFeature','central_air_Y','Location_Low','Location_LowMed','Location_MedHigh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = numeric_columns + dummy_columns4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = X[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(include_bias = False)\n",
    "X_poly = poly.fit_transform(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "kf = KFold(n_splits = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattg/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_model = LassoCV(cv = kf)\n",
    "lasso_model = lasso_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.63273182050736"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_optimal_alpha = lasso_model.alpha_\n",
    "lasso_optimal_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_quick = Lasso(alpha = lasso_optimal_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattg/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/mattg/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/mattg/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81032253, 0.85569173, 0.8577275 ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lasso_quick, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
